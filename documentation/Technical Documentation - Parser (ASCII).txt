=============================================
C++ PL COMPILER PROJECT

Parser for the Programming Language PL

Written for 
CPSC 4600 - Compiler Design

Written in C++.

Written By:
-Chad Klassen
-Jordan Peoples
-Adam Shepley

Version 3 - Code Generation Parser Revision
Created between February 1st and March 1st.
Second Revision April 2nd, 2012
Third Revision April 20th, 2012.
=============================================


*****************NOTE*****************************
Please check sections E5 and F6 for Scope and Type information. 
**************************************************

****************NOTE******************************
Please check section G7 for information about the code-generation
process of this compiler, and the relevant information within that.
**************************************************

It should be explicitly noted that, as specified in the README, this documentation is
 created and exists apart from the original Scanner documentation.

The reason for this is that is allows us to maintain the original documentation in an
unperturbed and accurate version of the original documentation for specific scanner components,
and allows us to maintain the insights into certain design decisions that may conflict or 
may result in seemingly confusing design choices for future versions of the compiler.

Which is to say, at the moment, certain components of the Scanner are not explicitly/directly
used or used differently or altered by the Parser;

The major change in the program structure, apart from adding the Parsing components, is that
the Parser itself now controls the call to the Scanner's Scan() function through the Admin object.

However, Admin's error handling and various wrappings around the Scanner are still applied, so
there is not much (at the current stage) in the way of a specific shift in regards to how the 
Scanning is completed and where and when and why.

While the Scanner is now invoked by the Parser during the (logical) construction of the Parse tree,
the Scanner's internal representation is near-wholly unchanged apart from corrections to some 
tokenizing functions and return variables.

The Scanner still performs and functions essentially the same as it had before, which is why it seems
best to keep the Parser's uniqueness (and the following changes to the other classes such as Admin)
within this distinct, easier to "parse" Documentation file.

At a later dat, such as the final revision of the Parser, the documentation as a whole may be combined
or refined into a final format and representation.


================================================

INDEX
-----

The following is a light index of the Parser Documentation.
I do not feel it is necessary, but feel free to use it to jump to a given section by searching.
This documentation is a more streamlined, general approach to documenting the given files and
classes, and as such will be significantly shorter than the Scanner documentation.

At some later point, they may be combined, but the separation makes it easier to understand
and read both components at the moment.

<A1> Overview
  (A1.1) Overview
  (A1.2) Changes to Existing Files, Code and Objects

<B2> Parser Object
  (B2.1) Overview, Function Types
  (B2.2) Explicit Functions
  (B2.3) Functional Representation of Non-Terminal Grammar Components

<C3> Set Object
<D4> First Object

*********************Scope and Type Check*******

<E5> BlockTable Scope Object
<F6> Scope and Type Check Additions - Semantic/Static Verification

*********************Code Generation************

<G7> Generation and Assembly of PL Program Code as Instructions


================================================


<A1> - OVERVIEW
----------------------
(A1.1) Overview
----------------------

The PL Recursive Descent Parser as a whole isn't a very complex component in regards to 
how it actually functions from a higher level point of view.

The PL Parser (or rather, the PL Compiler at the Parsing stage) performs the basic role of 
parsing the input file while it tokenizes it - creating a logical "parse tree" (in the
form of a function hierarchy) and using the Scanner and its components to construct the necessary
components (such as the symbol table) for later Parsing duties.

The Parser uses the Scanner to grab a token and to peek at the next one; it then decides, based
off of a series of production and syntactic and semantic rules (i.e. the Grammar of the PL language)
which tree of function calls to follow in order to come to a correct conclusion about the 
code in the source file. A successful conclusion being either than a given statement or line of code
is syntactically/semantically correct or not.

This is accomplished by a predefined set of functional paths and conditionals therein, which use 
something called a First set to create sets that decide (when matched) whether a substring can still
continue to be parsed, whether a syntax error has been reached, or if a file has been parsed correctly.
When an item is not within the first or stop sets, it failes a syntax check and prompts an error.

In addition to this, there is of course basic error handling and output capabilities, and the Parser 
is constructed in a recursive manner that allows it to successfully continue to attempt to parse the
rest of a source file if a syntax error is recovered. That is, it incorporates a form of
error recovery.


----
----
(A1.2) Changed to Existing Files, Code and Objects
--------------------------

As we have yet to truly expand upon the scope and semantic analysis, the changes to existing data
structures such as the symbol table or Token class have been minimal.

However, a few basic changes have been made that should be noted:

In Admin.cpp and Admin.h, the Admin object now constructs a Parser object upon construction, and 
passes it a pointer to said Admin object.
Next, since the Parser now has direct control of the Scanner, the Admin class' scan() function now tells
the Parser to Run through run();
Finally, NextToken is now directly accessed through the Parser, which has internal facilities for
handling bad tokens and such.

However, the Admin itself still maintains the same error reporting and general control structures it had 
in the first revision of the compiler.

In Scanner.cpp and Scanner.h, the Scanner now properly handles Reserved words and accesses the Symbol
Table accordingly. Additionally, the proper lexeme name/type for a token is returned now - explicitly,
such as "name".

Apart from these, there have been no significant changes to the existing files and Compilation
objects, which (as outlined above) is the reason for the segregated readme's.


==================================


<B2> Parser Object
------------------------------
(B2.1) Overview, Function Types
------------------------------

The Parser is responsible for properly syntactically verifying that the input is correct, and (virtually) 
forming a syntax and grammatical parse tree from the scanned input.
It accomplishes this by linking back to the Scanner through the Admin, using it to grab a given Token, 
then intelligently proceeding to the next set of proper steps in the Grammatical structure of the PL Language.

In essence, the Parser accomplishes its tasks by utilizing two distinct classes of functions:
Grammatical Non-terminal functions, and control/syntactic/verification functions.

Non-Terminal Functions -

The Parser object has a large set of functions that are used to parse a file.
These functions interlink in such a way as to satisfy the specific Grammar of PL as outlined in the
Per Brinch Hansen book. 
Which is to say, each function is the logical equivalent of a Non-Terminal of the Grammar, with a given
function body performing the tasks of the Production Bodies of the given terminals.

Programmatic control structures, such as IF(X OR Y)...ELSE statements allow a given function to act as
a multiple-production non-terminal.
As mentioned earlier, any ambiguities regarding the language's grammar itself were adjusted for in 
creating the functions; at that, the function names may not exactly match the given Grammar names.

When executed, these functions form a logical tree that corresponds to the parse tree for the input
file - and in the process of attempting to form said structure, discovers any syntax errors in the file.


Control/Syntactic/Verification Functions -

These are functions such as Match, syntaxError, syntaxCheck, nextToken, debug and run.
These functions are used by the Non-terminal functions to check the various inputs they encounter, to access
the scanner and proceed through the input file, to output error and debug information tot he screen and to 
check a given lexical sequence for a syntax error.


----
----
(B2.2) Explicit Functions
--------------------------


Specific Functions:

The following functions are outlined explicitly as they perform specific tasks that are crucial to 
understanding how the parser operates.

run() - 
The main function of the parser, which is called from the Admin class.
It creates a base stopset with the accept character '$', then applies it to the first Non-Terminal in the PL
language, Program().

debug() - 
This is a function that outputs the given Parsing information to the screen, particularly where we are in
the file and what level of the logical tree we are located at.
It is called with a macro as its paramaeter - __func__ - which presents the function name inside.
If the Parser prompts a compilation error, your compiler may not be recognizing the standard Macro.

nextToken() - 
Responsible for calling the nextToken function of Admin (and thus the Scanner) and accounting for any
scan errors that arise.
It is important to note that while the Admin reports and accounts for scan errors, the Parser must explicitly
ensure that it requests tokens until it receives a valid one, as the Grammar itself does not have production
rules for non-language components.

match() - 
This function verifies that the current and next token/given lexeme is in the valid set of next possible
characters in the language and source file; that is, it uses the set created thus far in Parsing to ensure 
that the token that has just been read is syntactically valid, and calls the appropriate error handler if it
is not.

syntaxError() - 
This function outputs the given syntax error and the debugging information (i.e. line number) to the screen,
then ensures that the Scanner is advanced along the input until a new parsable section of tokens is presented.

syntaxCheck() - 
Similar to the syntaxError function, this function calls the error function if the next segment of code 
is syntactically wrong.


----
----
(B2.3) Functional Representation of Non-Terminal Grammar Components
-------------------------------------------------------------

The Grammar:
The following is a set of Production-Rule functions. Each one has a specific speciality in regards to how 
they treat their input and production rules, but on the whole they follow a similar key process:

* 1) Output the function name and data.
* 2) Choose a production rule to follow based off of the lookahead
* 3) Try to Match any prerequisite statements or rules
* 4) Append any valid lexemes to the StopSet sts
* 5) Choose a production rule and follow it (a non-terminal)
* 6) Repeat ~3-5 unless an error is found
* 7) Attempt to match the post-requisite statement/lexeme/rule.
* 8) Check the validity of the lookahead in regards to the stopset sts

Though each specific function has its own, unique heuristics for parsing/representing the grammatical
rules of the PL language. Refer to the PL Grammar itself or the source code to see the minutia.

  void Program(Set sts);
  void Block(Set sts);
  void DefinitionPart(Set sts);
  void Definition(Set sts);
  void ConstantDefinition(Set sts);
  void VariableDefinition(Set sts);
  void VariableDefinitionPart(Set sts);
  void TypeSymbol(Set sts); 
  void VariableList(Set sts);
  void ProcedureDefintion(Set sts);
  void StatementPart(Set sts);
  void Statement(Set sts);
  void EmptyStatement(Set sts);
  void ReadStatement(Set sts);
  void VariableAccessList(Set sts);
  void WriteStatement(Set sts);
  void ExpressionList(Set sts);
  void AssignmentStatement(Set sts);
  void ProcedureStatement(Set sts);
  void IfStatement(Set sts);
  void DoStatement(Set sts);
  void GuardedCommandList(Set sts);
  void GuardedCommand(Set sts);
  void Expression(Set sts);
  void PrimaryOperator(Set sts);
  void PrimaryExpression(Set sts);
  void RelationalOperator(Set sts);
  void SimpleExpression(Set sts);
  void AddingOperator(Set sts);
  void Term(Set sts);
  void MultiplyingOperator(Set sts);
  void Factor(Set sts);
  void VariableAccess(Set sts);
  void IndexedSelector(Set sts);
  void Constant(Set sts);
  void Numeral(Set sts);
  void BooleanSymbol(Set sts);
  void ConstantName(Set sts);
  void VariableName(Set sts);
  void ProcedureName(Set sts);
  void FactorName(Set sts);

These align precisely to the refined grammar of the PL language.
Should the Parser reach the end of a given tree of instructions, then this means
that the given segment was syntactically correct.

Recursively, it will reach the end of the file and end up comparing to the "."
character, indicating a wholly correct program.

----

As mentioned earlier, the Parser makes use of a Stop set and what's known as a First set.
Additionally, it (implicitly!) makes use of the Follow sets of certain nonterminals.
A Set is an object that will be defined later, and First is a static function set that
returns members of the First set that correspond to a given nonterminal.

For now, it suffices to say that the Parser makes explicit use of the First set by 
using it to compliment the set of applicable and acceptable syntax components when
parsing a given line.



============================================


<C3> Set Object(s)
-------------------------


The bulk of the documentation and the logical work is handled by the Parser above.
Thus, the following documentation is short merely because the Set object is quite simple.

The Set Object is essentially just a wrapper for a Vector of Strings that we use to get a 
more logical/math-accurate representation of a "set".
I.E. a set in the form of {e1, e2, e3, e4, ..., en} and so on.

Though we say "strings", we are really referring to more of a type of Lexeme data.

The set object itself provides functions for accessing and "altering" set data;
A toString function returns a representation of the total set in the form outlined above, 
but all of the "alteration" functions (except add) actually return a copy of the Set in
order to maintain integrity within a given program stack/recursive section of the 
parsed grammar.

The SET object is used extensively by the Parser and the First objects; the former using
Sets for the parsing itself, and the latter being composed enitrely of set objects.
An overarching Set stopset "sts" is "passed" between nonterminal functions and their 
productions and is used to mediate the Matching; Said stop set contains the valid values 
for continuing to parse, and a lack of a specific value within it indicates a syntax error.


=======================================================


<D4> First Object
------------------------

Much like the Set object, the First object is a simple object that has a very simple
explanation.

The First object is essentially a library/collection of Static functions that are
pretyped and predeclared. These functions all return the given First() entry for a 
given Grammar non-Terminal, such as Program.

Which is not to say they're explicitly pre-typed; the First set will perform the computations
needed to attain the first set of a given nonterminal, though said computation is essentially
just recursively grabbing the First set of the given nonterminal in it sproductions and
creating a union of said productions as well.

The First Object is a static object, and needs only be included, rather than declared.

For an example of its use, see the Block nonterminal function in Parser:

void Parser::Block(Set sts)
{
  debug(__func__, sts, lookAheadToken);
  Set* temp = new Set("end");

  
  match         ("begin",sts.munion(First::DefinitionPart()).munion(First::StatementPart()).munion(*temp));
  DefinitionPart(sts.munion(First::StatementPart()).munion(*temp)); 
  StatementPart (sts.munion(*temp)); 
  match         ("end", sts);
  
  syntaxCheck(sts);
  
  
}

wherein we can see that we construct a set from the First sets of Block and, funamentally, DefinitionPart and 
StatementPart.

****************************************************************************************************************
=======================================================
****************************************************************************************************************

As this is a subcomponent of the Parser, we have added it as a stipend to the current documention, appended so as to preserve
the original outlined style of the Parser.

=======================================================


<E5> The BlockTable
------------------------

In order to accomodate the Scope and Type checking in the following section, we have created
a new Object called a BlockTable.

This object manages a collection of a new record type called a TableEntry; a TableEntry struct is defined as follows:

typedef struct {

	 //integer code for ID
	int id;
	
	//Kind is an enum type to represent objects Kind e.g. CONSTANT VARIABLE ARRAY PROCEDURE UNDEFINED
	Kind okind;
	
	//mType is an enum type to represent datatypes in PL e.g. Integer Boolean Universal ConstantInteger, ConstantBoolean
	mType otype;
	
	//Only for array types this entry will be filled. All others will have zero
	int size;
	
	//Only for constants
	int value;	
	
} TableEntry; //Logical "Extension" of a Token's consolidated representation
(direct from code)

It is a structure that accomodates a couple of enums (Kind and mType) which determine the Type and Kind of a given TableEntry;
A TableEntry itself is a logical and literal representation of a "completed" token object entry in aline of code.
i.e. we could have TableEntry X, which is a constant integer and contains a value of, say, 5.

The Parser uses these TableEntry structures in checking specifics about logical programming constructs, specifics such as if
a given object has been declared (in name) before, or if its value can be evaluated or assigned properly
(i.e. that we aren't assigning a 4 to a Boolean type, or that we aren't trying to re-assign a Constant variable. )


The BlockTable object contains a local "Block" which is a vector of these tableEntries, and provides numerous
facilities for editing and accessing such blocks and their component table entries; additionally, it contains a
vector of such "Blocks" (a Vector of a Vector of TableEntry pointers) that equates to the Logical Scope of a programming
language.

In other words, the Parser keeps track of the Scope and a given scope's objects by keeping track of the current Scope 
(as represented by a block) and all entries in it, and by keeping a Stack of previous blocks above that;
When a block reaches the end of its life (i.e. end of scope) it is removed from the stack (or current scope) when necessary.

Scope and Type checking are accomplished therein by checking the Types of the given TableEntry's that correspond to the current
logical programming object being looked at by the Parser, and comparing it to any previous iterations (or lack thereof)
in the table (vector) of blocks (table entry vectors).

These tableEntries are constructed by using the SymbolTable from the Scanner when necessary.

For more information, please see BlockTable.h and BlockTable.cpp.


======================================================

<F6> Scope and Type Checking Additions - Semantic/Static Verification
---------------------------------------------------------------------

The following is a set of Function/Production altercations that were made to accomodate scope and type checking;
Ultimately, this was accomplished by chaining and passing the relevant and proper Types from the "bottom" or end-productions
of the Parser parse tree, and verifying along each step that they correspond to the logical programming constructs'
grammar requirements.

For example, guaranteeing that a GuardedCommand is properly evaluated and formulated, or that a PrimaryExpression evaluates
to the proper, prompt type.

For more information, see Parser.cpp, Parser.h, and section <E5>.
Where necessary, refer to the function header or inline comments associated with each production in the class definition file.

The following is a Production-By-Production / Function-by-Function Grammatical breakdown of the individual handling of type checking semantics.

NOTE: Throughout the whole of the Scope and Type checking semantics, we use a Universal type largely as an Error type of table entry type;
it indicates that we have encountered something that does not fit in properly with the production rule it has been divined from.


Parser::Block
-a newBlock is created in the blockTable before DefinitionPart, then the block is ended/removed after the end of StatementPart

Parser::DefinitionPart
-a blockType is pushed onto the blockTypeStack (DEFINITIONPART) while we call the next Definition tokens, and it is popped once the definitionPart of this Block reaches the end (the while loop lookaheadtoken is not a Definition)

Program::VariableDefinition
-Passes the type of a TypeSymbol to VariableDefinitionPart, allowing VDP to know if it needs to create an Array or process a normal Variable kind.


Parser::VariableDefinitionPart
-Checks to verify what KIND of variable is being defined. If it's an array, we grab a set of ids from VariableList (see bwlow)
and the valid constant and attempt to find the valid entry in the blocktable if a predefined variable is used.
As the array is created, we ensure that each blocktable tableentry is valid and expand the given Array entry in the blocktable correspondingly.
(Blocktable->redefineSize())
Alternatively, we simply try to generate a VariableList of kind VARIABLE using our current type.


Parser::VariableList
-Now returns a vector of Integers corresponding to the valid tokenIDs of the variables that are being found in the list.
By adding to the blocktable, the implicit blocktable checks for repitition allows us to catch repeat variable definitions inside
of the variable list.
Also processes a single variable explicitly as well.

Parser::ProcedureDefinition
-Now defines the Procedure by Name, as a PROCEDURE and UNIVERSAL TYPE in the blocktable, allowing it to be retrieved
at a later scope;
By calling the check, it guarantees that there will be no multiple definitions and thus ambiguous/nondeterministic calls to
the procedure will not happen.


Parser::StatementPart
-Now adds and pops the blocktype of StatementPart to the blocktypestack, guaranteeding that the eventual comparison can
be made; if it ends not-empty, there will be a parse error.

Parser::Statement
-Calls the corresponding guards for If/Do in addition to standard parsing, guaranteeing that the guards are properly considered.

Parser::VariableAccessList
-Returns a vector of variable types corresponding to the returns from the VariableAccess productions (list variables)

Parser::ExpressionList
-Returns a Vector of mTypes that correspond to the types of expressions in the list of expressions, thus assuring coverage of multiple expressions in a list, regardless of varying types.

Parser::AssignmentStatement
-Uses two mType vectors and processes the valid VariableAccessList and ExpressionList components, furthermore comparing
the selected types in each to verify that they are all assignable and that, specifically, a list component on the left hand side
of the assignment corresponds to an identical (type/kind-wise) list on the right hand side of the assignment.

Parser::ProcedureStatement
-Guarantees the Scoping of procedures is correct by checking for the Procedure name as being defined in a previous block, and processing errors as necessary

Parser::IfStatement
-Similar to DoStatement, verifies that the If/fi requirements are met and processes the guarded command list.

Parser::DoStatement
-Verifies that the Do command and the subsequent Guarded command processes as necesary.

Parser::GuardedCommandList
-Verifies that the GuardedCommands are valid, and each subsequent guarded command in the list is valid as well.
It does not need to chain any types upward.

Parser::GuardedCommand
-Gathers the type of the coinciding, following Expression part, and then guarantees that the StatementPart follows.
The guard fails if no kind of boolean resultant evaluation type is detected (constant or normal).


Parser::Expression
-Returns an mType evaluating the type resultant from the corresponding primary expressions (and operators therein between.)
If there are multiple primary expressions, it consolidates their types to determine if a valid one is present (INTEGER),
and then returns a UNIVERSAL (error) type if otherwise.

Parser::PrimaryExpression
-Ultimately returns a boolean mType to the caller Production, but determines that it should use that type by examining the series of simpleExpressions and relational operators that follow;
For insteance, a SimpleExpression by itself could just be a Factor following a construct specifier (such as ( or ~) or it could be a simpleExpression followed by a possible relational operator.
Without the following operator, it would need to be boolean, but with it, they could be any equitable boolean operating component; however, PrimaryExpression will properly compare the types and return a Boolean if it was a valid comparison, or an error type (Universal) if otherwise.
This likewise includes comparing our new types, CINTEGER and INTEGER or CBOOLEAN and BOOLEAN.

Parser::SimpleExpression
-Returns a proper mType after checking the types corresponding to the adding operators; it must evaluate to an integer in the end.
-The validation logic is similar to term; see below. This follows from PrimaryExpression's requirements; See above.

Parser::Term	This is a central Production/function.
-A term is composed of Term = Factor { MultiplyingOperator Factor } and thus can contain multiple Factor types.
Thus, we grab them all and then check to see what kind they are; for multiple ones, we return a relevant Integer or Universal type (otherwise, we will get a mismatch).
If there's only 1 (A Term can be one or many Factors separated by MultiplyingOperators), then we return that type.
Ultimately, we either return a Boolean, Integer, CBoolean or CInteger (constant variations) as that's what a Term could be. BUT, a Universal type indicates multiple terms that need to be identically matched.

Parser::Factor
-Returns the mType of the given Factor, whether it is a Constant, a VariableName (FactorName), or a corresponding Expression's type.

Parser::FactorName
-returns the mtype of a numeral or boolean, or the type that the VariableName (if it is one) corresponds to.

Parser::VariableAccess
-returns the mtype of the corresponding VariableName
-does not handle a Factor production; Unambiguous new production FactorName does this.

Parser::IndexedSelector
-We determine the type of the selector and then produce an error if it isn't of an integer type. We check it as an expression, which handles the type determinism inside itself.

Parser::ConstantName
-returns the mtype of booleansymbol, ConstantName or Numeral

Parser::Numeral
-returns an INTEGER mtype

Parser::BooleanSymbol
-returns boolean mtype

Parser::ConstantName
-mtype return (universal/const)

Parser::VariableName
-We set the type of a VariableName by checking the kind of variable and its corresponding entry's oType.
I.e. A constant Integer.
If we're in the definition part, it's of a Universal type.
Otherwise, we search for it...if it isn't found, then we're using an undeclared variable.

--------------------------------------

By making the above changes to the given functions, we've allowed for semantic and syntactic additions and
logic to account for Scope and Type Parsing problems and considerations.





***************************************************************************************

=================================================================

<G7> Generation and Assembly of PL Program Code as Instructions
---------------------------------------------------------------------

As the nontrivial parts of the code generation were completed already, we take only a short
section here to explain the general structure and process of our code-generation procedure(s).

Ultimately, our Parser is supposed to eventually output some form of three-address code
that is to be read by an Assembler, which then creates "binary" (pseudo-binary) code
for the given Interpreter or execution environment.

With our PL compiler, we are using a separate (but included) Interpreter, and the
included assembler of outside design is used to target that Interpreter with a 
series of instructions. These instructions are created by using the three-address
code generated by our Compiler/Parser.

Said Assembly code is stored in an ASM ("test.asm") file and a local StringStream, and the corresponding
Interpreter code is stored in an Interpreter file ("interpInput.itp")

The generation of this code is done by the Parser; in any place where a given specific
machine instruction would need to be executed or called, we generate a corresponding
intermediary set of code, such as 
VARIABLE
0
8
which (in the end) leads the Interpreter to call the Variable function with the parameters
0 and 8.
Instructions of this sort, and of lesser variety, are used to convert a PL statement to a symbolic one
that can be passed over and used to create meaningful stack and bit operations.

In our case, the Assembler converts this to an instruction that manipulates the Interpreter
stack and calls functions accordingly, in a black-box fashion<G7> Generation and Assembly of PL Program Code as Instructions (to the outside reader of
the binary .itp files).


Our compiler generates this code as it parses a PL file; thus, it starts contruct the file
as it parses the PL source code.
This Assembly string is then sent to a file and then to the Assembler, which attempts to 
construct an itp file by calling corresponding functions for each line in the assembly file.

Essentially, we are doing a symbolic, unresolved pass of the code, and then a second pass
occurs that actually resolves the forward references and outputs meaningful assembly-interpreter
instructions.

In order to get the external Assembler to work with out code, we augmented the Second Pass
function to take a string copy of the original source file again.

Ultimately, we generate three-address code corresponding to the following set of instructions:
-Add, And, Arrow, Assign, Bar, Call, Constant, Divide, EndProc, EndProg, Equal, Fi, Greater,
Index, Less, Minus, Modulo, Multiply, Not, Or, Proc, Prog, Read, Subtract, Value,
Variable and Write.

Each of these instructions has one to two additional parameters as integer, thus our ASM files consist of
a series of INSTRUCTIONs followed by one or two numbers.

To see precise information of how these instructions are laid out, please see both Parser.cpp and
Interp.h and Interp.cpp.

In order to view the intermediary symbolic code, add the -g flag when running the ./main compiler.